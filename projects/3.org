Coding project 3: neural network for binary classification.

For this project you will be implementing a stochastic gradient
descent algorithm for a neural network with one hidden layer.

** Algorithm: stochastic gradient descent with early stopping regularization
Function name: NNetOneSplit
- Inputs: X.mat (feature matrix, n_observations x n_features), y.vec
  (label vector, n_observations x 1), max.iterations (int scalar > 1),
  step.size, n.hidden.units (number of hidden units), is.train
  (logical vector of size n_observations, TRUE if the observation is
  in the train set, FALSE for the validation set).
- Output: list/dictionary/etc with at least three named elements:
  - V.mat best weight matrix (n_features x n.hidden.units), used to
    predict hidden units given inputs.
  - w.vec best weight vector (n.hidden.units), used to predict output
    given hidden units.
  - loss.values, a matrix/data.table/etc which stores the logistic
    loss with respect to the train/validation set for each iteration.
- the algorithm should initialize V.mat/w.vec to some random numbers
  close to zero (e.g. using rnorm in R).
- During each iteration from k=1 to max.iterations you should compute
  the gradients of V.mat/w.vec with respect to a randomly selected
  observation, then update V.mat/w.vec by taking a step (scaled by
  step.size) in the negative gradient direction.
- At each iteration you should compute the logistic loss on the
  train/validation sets, and store those in loss.values.
- After max.iterations you should compute a variable called
  best.iterations which is equal to the number of iterations that
  minimizes the validation loss.

** Experiments/application

- Use spam data set from
  [[https://web.stanford.edu/~hastie/ElemStatLearn/data.html]]
- First scale the inputs (each column should have mean 0 and variance
  1). You can do this by subtracting away the mean and then dividing
  by the standard deviation of each column (or just use a standard
  function like scale in R).
- (10 points) Use NNetOneSplit with the whole data set as
  X.mat/y.vec. For is.train, randomly assign 60% train and 40%
  validation.
- (10 points) Plot the train/validation loss as a function of the
  number of iterations, and draw a point to emphasize the minimum of
  each curve.
- (10 points) the train loss should always go down, whereas the
  validation loss should go down and then start going up after a
  certain number of iterations. If it does not, try decreasing
  step.size and increasing max.iterations.
- (10 points) Use 4-fold cross validation to compare the prediction
  accuracy of two algorithms: (1) baseline/underfit -- predict most
  frequent class, (2) NNetOneSplit. Plot the resulting test accuracy
  values as a function of the data set. Example:

[[file:2-test-accuracy.png]]

*** Grading rubric 

Your final grade for this project will be computed by multiplying the
percentage from your [[file:group-evals.org][group evaluations]] with your group's total score
from the rubric above.

Your group should submit a PDF on BBLearn. 
- The first thing in the PDF should be your names and student ID's
  (e.g. th798) and a link to your source code in a public repo
  (e.g. github, there should be no code in your PDF report).
- The second thing in the PDF should be your group evaluation scores
  for yourself and your teammates.

Extra credit: 
- 10 points if your github repo includes a README.org (or README.md
  etc) file with a link to the source code of your GradientDescent
  function, and an explanation about how to run it on the data sets.
- 10 points if you show GradientDescent (from project 1, logistic regression with
  number of iterations selected by a held-out validation set) in your
  test accuracy figure as a baseline.
- 10 points if you show NearestNeighborsCV (from project 2) in your
  test accuracy figure as a baseline.
- 10 points if you compute and plot ROC curves for each (test fold,
  algorithm) combination. Make sure each algorithm is drawn in a
  different color, and there is a legend that the reader can use to
  read the figure. Example:

[[file:1-ROC.PNG]]
  
- 10 points if you compute area under the ROC curve (AUC) and include
  that as another evaluation metric (in a separate panel/plot) to
  compare the test accuracy of the algorithms.
  
** FAQ

- how to debug R code? you should use traceback() to find out where
  the error is happening, the put print statements or browser() on the
  line just before the error, so you can see what is going on and
  debug.
- Given only 2 data points (or any even number), how do you make sure the algorithm functions properly?  For example, with 2 nearest neighbors, if one neighbor is 0 and the other is 1, how do we predict the current value? Given an even number of neighbors in binary classification, there is a possibility of a tie. In that case there are various rules for breaking the ties (e.g. select one of the classes at random, select the most frequent class in the train data) and hopefully it doesn't matter which rule you use. One of them should be implemented in whatever library function you are using (e.g. class::knn in R uses the random selection).
- for making data tables to visualize using ggplot2 you may want to use [[http://members.cbio.mines-paristech.fr/~thocking/animint2-manual/Ch17-appendix.html#list-of-data-tables][the list of data tables idiom]].
