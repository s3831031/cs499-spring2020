K-fold cross-validation for hyper-parameter tuning and model comparison

In this project your goal is to implement K-Fold cross-validation,
then use it with machine learning algorithms to (1) train
hyper-parameters and (2) compare prediction accuracy.

*** Algorithm/function: KFoldCV

The goal of this exercise is to code the K-Fold Cross-Validation
algorithm.
- (10 points) You should code a function KFoldCV which should take as
  input arguments:
  - X_mat, a matrix of numeric inputs (one row for each observation, one column
    for each feature).
  - y_vec, a vector of binary outputs (the corresponding label for each
    observation, either 0 or 1).
  - ComputePredictions, a function that takes three inputs
    (X_train,y_train,X_new), trains a model using X_train,y_train,
    then outputs a vector of predictions (one element for every row of
    X_new).
  - fold_vec, a vector of integer fold ID numbers (from 1 to K).
- (5 points) The function should begin by initializing a variable
  called error_vec, a numeric vector of size K.
- (20 points) The function should have a for loop over the unique
  values k in fold_vec (should be from 1 to K). During each iteration
  k you should
  - first define X_new,y_new based on the observations for which the
    corresponding elements of fold_vec are equal to the current fold
    ID k.
  - then define X_train,y_train using all the other observations.
  - then call ComputePredictions and store the result in a variable
    named pred_new.
  - then compute the zero-one loss of pred_new with respect to y_new
    and store the mean (error rate) in the corresponding entry of
    error_vec.
- (5 points) At the end of the algorithm you should return
  error_vec.

*** Algorithm: NearestNeighborsCV

- (5 points) You should code a function NearestNeighborsCV with input
  arguments
  - X_mat, a matrix of numeric inputs/features (one row for each
    observation, one column for each feature).
  - y_vec, a vector of binary outputs (the corresponding label for each
    observation, either 0 or 1).
  - X_new, a matrix of numeric inputs/features for which we want to
    compute predictions.
  - num_folds, default value 5.
  - max_neighbors, default value 20.
- (5 points) randomly create a variable called validation_fold_vec, a
  vector with integer values from 1 to num_folds.
- (5 points) initialize a variable called error_mat, a numeric matrix
  (num_folds x max_neighbors).
- (5 points) There should be a for loop over num_neighbors from 1 to
  max_neighbors.
- (5 points) Inside the for loop you should call KFoldCV, and specify
  ComputePreditions=a function that uses your programming language's
  default implementation of the nearest neighbors algorithm, with
  num_neighbors. e.g. [[https://scikit-learn.org/stable/modules/neighbors.html][scikit-learn neighbors in Python]],
  [[https://www.rdocumentation.org/packages/class/versions/7.3-15/topics/knn][class::knn in R]]. Store the resulting error rate vector in the
  corresponding column of error_mat.
- (5 points) Compute a variable called mean_error_vec (size
  max_neighbors) by taking the mean of each column of error_mat.
- (5 points) Compute a variable called best_neighbors which is the
  number of neighbors with minimal error.
- (5 points) Your function should output (1) the predictions for X_new,
  using the entire X_mat,y_vec with best_neighbors; (2) the
  mean_error_mat for visualizing the validation error.

*** Experiments/application
- Use spam data set from
  [[https://web.stanford.edu/~hastie/ElemStatLearn/data.html]]
- First scale the inputs (each column should have mean 0 and variance
  1). You can do this by subtracting away the mean and then dividing
  by the standard deviation of each column (or just use a standard
  function like scale in R).
- (10 points) Use NearestNeighborsCV on the whole data set, then plot
  validation error as a function of the number of neighbors,
  separately for each fold.
- (10 points) Draw a bold line for the mean validation error, and draw
  a point to emphasize the minimum.
- (10 points) Randomly create a variable test_fold_vec which is a
  vector with one element for each observation, and elements are
  integers from 1 to 4. In your report please include a table of
  counts with a row for each fold (1/2/3/4) and a column for each
  class (0/1). 
- (10 points) Use KFoldCV with three algorithms: (1) baseline/underfit
  -- predict most frequent class, (2) NearestNeighborsCV, (3) overfit
  1-nearest neighbors model. Plot the resulting test error values as a
  function of the data set, in order to show that the
  NearestNeighborsCV is more accurate than the other two models.

*** Grading rubric (out of 120 points)

Your final grade for this project will be computed by multiplying the
percentage from your [[file:group-evals.org][group evaluations]] with your group's total score
from the rubric above.

Your group should submit a PDF on BBLearn. 
- The first thing in the PDF should be your names and student ID's
  (e.g. th798) and a link to your source code in a public repo
  (e.g. github).

Extra credit: 
- 10 points if your github repo includes a README.org (or README.md
  etc) file with a link to the source code of your GradientDescent
  function, and an explanation about how to run it on the data sets.
  
